# LLM Dashboard Backend Configuration

# ============================================
# üîß GPU/CPU MODE FEATURE SWITCH
# ============================================
# Set to False when you have GPU available
# Set to True for CPU-only testing (slower, limited models)
FORCE_CPU_MODE=True

# API Configuration
API_V1_STR=/api
PROJECT_NAME=LLM Local Ops Center

# Model Cache Directory
MODEL_CACHE_DIR=/root/.cache/huggingface/hub

# vLLM Configuration
VLLM_BASE_PORT=8000
VLLM_MAX_INSTANCES=5

# WebSocket Configuration
WS_HEARTBEAT_INTERVAL=30

# ============================================
# üìù SWITCHING TO GPU MODE:
# ============================================
# 1. Ensure NVIDIA drivers and CUDA are installed
# 2. Verify with: nvidia-smi
# 3. Set FORCE_CPU_MODE=False in .env file
# 4. Restart the backend server
# ============================================
